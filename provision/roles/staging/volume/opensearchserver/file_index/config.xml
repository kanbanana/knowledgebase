<?xml version="1.0" encoding="UTF-8"?><configuration>
<indices>
<index searchCache="100" filterCache="100" fieldCache="500" termVectorCache="0" maxNumSegments="1"/>
</indices>
<schema>
<analyzers>
<analyzer name="AutoCompletionAnalyzer" lang="">
<tokenizer class="StandardTokenizer"/>
<queryTokenizer class="StandardTokenizer"/>
<filter class="ShingleFilter" max_shingle_size="5" min_shingle_size="1" scope="QUERY_INDEX" token_separator=" "/>
<filter class="PrefixSuffixStopFilter" ignore_case="true" prefixList="English stop words" scope="QUERY_INDEX" suffixList="English stop words" token_separator=" "/>
<filter class="PrefixSuffixStopFilter" ignore_case="true" prefixList="French stop words" scope="QUERY_INDEX" suffixList="French stop words" token_separator=" "/>
<filter class="PrefixSuffixStopFilter" ignore_case="true" prefixList="German stop words" scope="QUERY_INDEX" suffixList="German stop words" token_separator=" "/>
</analyzer>
<analyzer name="DecimalAnalyzer" lang="">
<tokenizer class="KeywordTokenizer"/>
<queryTokenizer class="KeywordTokenizer"/>
<filter class="NumberFormatFilter" defaultValue="" inputDecimalSeparator="." inputGroupSeparator="," inputNumberFormat="#,##0.00" numberFormat="&amp;apos;&amp;gt;&amp;apos;0000000000.##########;&amp;apos;&amp;lt;&amp;apos;0000000000.##########" outputDecimalSeparator="." outputGroupSeparator="," scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="GeoDegreesAnalyzer" lang="">
<tokenizer class="KeywordTokenizer"/>
<queryTokenizer class="KeywordTokenizer"/>
<filter class="DegreesRadiansFilter" degrees_radians_conversion="Degrees to Radians" fault_tolerant="true" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="GeoRadianAnalyzer" lang="">
<tokenizer class="KeywordTokenizer"/>
<queryTokenizer class="KeywordTokenizer"/>
<filter class="DegreesRadiansFilter" degrees_radians_conversion="Check radians" fault_tolerant="true" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="IntegerAnalyzer" lang="">
<tokenizer class="KeywordTokenizer"/>
<queryTokenizer class="KeywordTokenizer"/>
<filter class="NumberFormatFilter" defaultValue="" inputDecimalSeparator="." inputGroupSeparator="," inputNumberFormat="#,##0.00" numberFormat="&amp;apos;&amp;gt;&amp;apos;0000000000;&amp;apos;&amp;lt;&amp;apos;0000000000" outputDecimalSeparator="." outputGroupSeparator="," scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="KeywordLikeAnalyzer" lang="">
<tokenizer class="KeywordTokenizer"/>
<queryTokenizer class="KeywordTokenizer"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="LongAnalyzer" lang="">
<tokenizer class="KeywordTokenizer"/>
<queryTokenizer class="KeywordTokenizer"/>
<filter class="NumberFormatFilter" defaultValue="" inputDecimalSeparator="." inputGroupSeparator="," inputNumberFormat="#,##0.00" numberFormat="&amp;apos;&amp;gt;&amp;apos;00000000000000000000;&amp;apos;&amp;lt;&amp;apos;00000000000000000000" outputDecimalSeparator="." outputGroupSeparator="," scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="NgramAnalyzer" lang="">
<tokenizer class="StandardTokenizer"/>
<queryTokenizer class="StandardTokenizer"/>
<filter class="NGramFilter" max_gram="7" min_gram="4" scope="INDEX"/>
</analyzer>
<analyzer name="PhoneticAnalyzer" lang="">
<tokenizer class="StandardTokenizer"/>
<queryTokenizer class="StandardTokenizer"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter beiderMorseRule="EXACT" class="PhoneticFilter" codec="Beider Morse" maxPhonenes="10" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="StandardAnalyzer" lang="">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="SuggestionAnalyzer" lang="">
<tokenizer class="StandardTokenizer"/>
<queryTokenizer class="StandardTokenizer"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="EdgeNGramFilter" max_gram="100" min_gram="1" scope="QUERY_INDEX" side="front"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="ar">
<tokenizer class="ArabicLetterTokenizer"/>
<queryTokenizer class="ArabicLetterTokenizer"/>
<filter class="ArabicNormalizerFilter" scope="QUERY_INDEX"/>
<filter class="ArabicStemFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="cz">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="CzechStemFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="da">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballDanishFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="de">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballGermanFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="en">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="SnowballEnglishFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="es">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballSpanishFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="fi">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballFinnishFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="fr">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="FrenchStemFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="it">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballItalianFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="ja">
<tokenizer class="CJKTokenizer"/>
<queryTokenizer class="CJKTokenizer"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="kr">
<tokenizer class="CJKTokenizer"/>
<queryTokenizer class="CJKTokenizer"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="nl">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="DutchStemFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="no">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballNorwegianFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="pl">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="PolishStemFilter" minLength="3" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="pt">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballPortugueseFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="ro">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballRomanianFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="ru">
<tokenizer class="RussianLetterTokenizer"/>
<queryTokenizer class="RussianLetterTokenizer"/>
<filter class="RussianStemFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="sv">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballSwedishFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="tr">
<tokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<queryTokenizer charArrayToken="" class="LetterOrDigitTokenizerFactory"/>
<filter class="LowerCaseFilter" scope="QUERY_INDEX"/>
<filter class="ISOLatin1AccentFilter" scope="QUERY_INDEX"/>
<filter class="SnowballTurkishFilter" scope="QUERY_INDEX"/>
</analyzer>
<analyzer name="TextAnalyzer" lang="zh">
<tokenizer class="ChineseTokenizer"/>
<queryTokenizer class="ChineseTokenizer"/>
<filter class="ChineseFilter" scope="QUERY_INDEX"/>
</analyzer>
</analyzers>
<fields default="content" unique="url">
<field name="lang" indexed="yes" stored="no" termVector="no"/>
<field name="title" analyzer="TextAnalyzer" indexed="yes" stored="yes" termVector="positions_offsets"/>
<field name="titleExact" analyzer="StandardAnalyzer" indexed="yes" stored="no" termVector="yes">
<copyOf field="title"/>
</field>
<field name="titlePhonetic" analyzer="PhoneticAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="title"/>
</field>
<field name="content" analyzer="TextAnalyzer" indexed="yes" stored="compress" termVector="positions_offsets"/>
<field name="contentExact" analyzer="StandardAnalyzer" indexed="yes" stored="no" termVector="yes">
<copyOf field="content"/>
</field>
<field name="contentPhonetic" analyzer="PhoneticAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="content"/>
</field>
<field name="url" indexed="yes" stored="no" termVector="no"/>
<field name="urlSplit" analyzer="TextAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="url"/>
</field>
<field name="urlExact" analyzer="StandardAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="url"/>
</field>
<field name="urlPhonetic" analyzer="PhoneticAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="url"/>
</field>
<field name="fileName" analyzer="TextAnalyzer" indexed="yes" stored="yes" termVector="positions_offsets"/>
<field name="fileNamePhonetic" analyzer="PhoneticAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="fileName"/>
</field>
<field name="fileNameExact" analyzer="StandardAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="fileName"/>
</field>
<field name="full" analyzer="TextAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="title"/>
<copyOf field="content"/>
<copyOf field="fileName"/>
<copyOf field="url"/>
</field>
<field name="fullExact" analyzer="StandardAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="title"/>
<copyOf field="content"/>
<copyOf field="fileName"/>
<copyOf field="url"/>
</field>
<field name="fullPhonetic" analyzer="PhoneticAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="title"/>
<copyOf field="content"/>
<copyOf field="fileName"/>
<copyOf field="url"/>
</field>
<field name="autocomplete" analyzer="AutoCompletionAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="title"/>
<copyOf field="fileName"/>
</field>
<field name="directory" indexed="yes" stored="no" termVector="no"/>
<field name="subDirectory" indexed="yes" stored="no" termVector="no"/>
<field name="crawlDate" indexed="yes" stored="no" termVector="no"/>
<field name="fileSystemDate" indexed="yes" stored="no" termVector="no"/>
<field name="fileExtension" indexed="yes" stored="no" termVector="no"/>
<field name="fileType" indexed="yes" stored="no" termVector="no"/>
<field name="fileSize" analyzer="LongAnalyzer" indexed="yes" stored="no" termVector="no"/>
<field name="userAllow" indexed="yes" stored="no" termVector="no"/>
<field name="userDeny" indexed="yes" stored="no" termVector="no"/>
<field name="groupAllow" indexed="yes" stored="no" termVector="no"/>
<field name="groupDeny" indexed="yes" stored="no" termVector="no"/>
<field name="mega_content" analyzer="NgramAnalyzer" indexed="yes" stored="no" termVector="no">
<copyOf field="content"/>
</field>
</fields>
</schema>
<urlManager class="UrlManager"/>
<statistics>
<statistic type="SEARCH" period="MINUTE" maxRetention="60" writeToLog="no"/>
<statistic type="SEARCH" period="HOUR" maxRetention="24" writeToLog="yes"/>
<statistic type="SEARCH" period="DAY" maxRetention="30" writeToLog="yes"/>
<statistic type="UPDATE" period="HOUR" maxRetention="24" writeToLog="yes"/>
<statistic type="UPDATE" period="DAY" maxRetention="30" writeToLog="yes"/>
<statistic type="DELETE" period="HOUR" maxRetention="24" writeToLog="yes"/>
<statistic type="DELETE" period="DAY" maxRetention="30" writeToLog="yes"/>
<statistic type="OPTIMIZE" period="DAY" maxRetention="30" writeToLog="yes"/>
<statistic type="RELOAD" period="HOUR" maxRetention="24" writeToLog="yes"/>
<statistic type="RELOAD" period="DAY" maxRetention="30" writeToLog="yes"/>
</statistics>
</configuration>
